# -*- coding: utf-8 -*-
"""split to two videos.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14rDsCfNiu58aJEreM4HvzpzSPC7BdbXF

# THIRD PERSON DETECTION PART
"""

import warnings
warnings.filterwarnings('ignore')

# !pip install facenet_pytorch

import torch
from facenet_pytorch import MTCNN

yolo = torch.hub.load('ultralytics/yolov5', 'yolov5s')
mtcnn = MTCNN(keep_all=True)

# from google.colab import drive

# drive.mount('/content/gdrive/')

# take an image , return detected persons
def Get_Persons(img): 
    
    yolo.classes = [0]
    
    results = yolo(img)
    
    # results.show() # to show the image with detected objects
    
    return results

# take the result of YOLO, return pandas dataframe of that result
def getDataFrame(YOLOresult):
  return YOLOresult.pandas().xyxy[0]

# take an image,return an array of bounding boxes of detected faces
# every element in this array is like : [xmin , ymin, xmax ,ymax]
def Get_Faces(img):
  boxes, probs, landmarks = mtcnn.detect(img, landmarks=True)
  return boxes

# take person bounding box and face bounding box and return true if this face inside this person
def face_is_inside_person(person,face):
  xmin = max(face[0],person[0])
  xmax = min(face[2],person[2])
  ymin = max(face[1],person[1])
  ymax = min(face[3],person[3])
  
  xmax = max(xmax,xmin)
  ymax = max(ymax,ymin)

  area1 = (xmax-xmin)*(ymax-ymin)
  area2 = (face[2]-face[0])*(face[3]-face[1])
  return area1/area2 > 0.75

# take yolo result and mtcnn result and return a list of bounding boxes (persons have faces)
def get_persons_with_faces(YOLOresult,MTCNNresult):
  if YOLOresult is None:
    YOLOresult = []
  if MTCNNresult is None:
    MTCNNresult = []
  ret = []
  dataframe = getDataFrame(YOLOresult)
  for i in range(dataframe.shape[0]):
    xmin = dataframe.iloc[i]['xmin']
    xmax = dataframe.iloc[i]['xmax']
    ymin = dataframe.iloc[i]['ymin']
    ymax = dataframe.iloc[i]['ymax']
    person = [xmin,ymin,xmax,ymax]
    for face in MTCNNresult:
      if face_is_inside_person(person,face):
        ret.append(person)
  return ret

import cv2
import numpy as np

# take box1 and box2 and threshold,
# return true if the 2 boxes almost the same depending on thresold
def box2_is_same_box1(box1,box2,threshold):
  xmin = max(box1[0],box2[0])
  xmax = min(box1[2],box2[2])
  ymin = max(box1[1],box2[1])
  ymax = min(box1[3],box2[3])
  
  xmax = max(xmax,xmin)
  ymax = max(ymax,ymin)

  area1 = (xmax-xmin)*(ymax-ymin)
  area2 = (box1[2]-box1[0])*(box1[3]-box1[1])
  return area1/area2 > threshold

# helping funtion for get_streamers() function
def remove_old_history(clearAll,history,frameNumber,tolerence,minLength,streamers):
  Rem = []
  for his in history: 
    if frameNumber - his[5] - 1 > tolerence or clearAll:
      if his[5]-his[4]+1 >= minLength:
        streamers.append(his)
      Rem.append(his)
  for r in Rem:
    history.remove(r)
  Rem.clear()

# helping funtion for get_streamers() function
def update_history(possible,history,threshold,frameNumber):
  for pos in possible:
    find = False
    for his in history:
      hisBox = [his[0],his[1],his[2],his[3]]
      if (box2_is_same_box1(hisBox,pos,threshold)):
        find = True
        his[5] = frameNumber
        break
    if not(find):
      history.append([pos[0],pos[1],pos[2],pos[3],frameNumber,frameNumber])

# a streamer is a person with face who last in his position in screen for a while (many frames)
# THIS IS THE MAIN FUNCTION
def get_streamers(videoURL,tolerence,minLength,threshold,skip):
  # IM = []

  streamers = []
  cap = cv2.VideoCapture(videoURL)
  if (cap.isOpened()== False): 
    print("Error opening video stream or file")

  frameNumber = 0
  totalFrames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
  history = []
  while(cap.isOpened()):
    ret, frame = cap.read()
    frameNumber += 1
    
    if ret == True:
      if frameNumber % skip == 1 or frameNumber == totalFrames:
        frame_rgb = frame[..., ::-1]
        persons = Get_Persons(frame_rgb)
        faces = Get_Faces(frame_rgb)
        possible = get_persons_with_faces(persons,faces)
        
        remove_old_history(False,history,frameNumber,tolerence*skip,minLength,streamers)

        update_history(possible,history,threshold,frameNumber)
    ## DEBUGGING ##
      # for i in possible:
      #   f = cv2.rectangle(frame,(int(i[0]),int(i[1])),(int(i[2]),int(i[3])),(255, 0, 0),2)
      # if len(possible)>0:
      #   IM.append(f)
      # else:
      #   IM.append(frame)
      # if frameNumber>105:
      #   remove_old_history(True,history,frameNumber,tolerence,minLength,streamers)
      #   break
      # for H in history:
      #   print(H)
    else:      
      remove_old_history(True,history,frameNumber,tolerence,minLength,streamers)
      break
  
  cap.release()
  cv2.destroyAllWindows()

  return streamers#,IM

# take result from YOLO and an image, return following info about the biggest person in the image (which is the third person shooter):
# 1- distance to center (value between [0,1] higher mean closer) and 
# 2- its size in refernce to the whole image
def main_person_size_and_distanceToCenter(YOLOresult,img):
    dataframe = getDataFrame(YOLOresult)
    numberOfRows = img.shape[0]
    numberOfColumns = img.shape[1]
    dis = 1.0
    sz = 0
    for i in range(dataframe.shape[0]):
        xmin = dataframe.iloc[i]['xmin']
        xmax = dataframe.iloc[i]['xmax']
        ymin = dataframe.iloc[i]['ymin']
        ymax = dataframe.iloc[i]['ymax']
        cur = (xmax-xmin)*(ymax-ymin)/(numberOfColumns*numberOfRows)
        if sz < cur:
            sz = cur
            centerX = xmin + (xmax-xmin)/2
            diff1 = abs( numberOfColumns/2 - centerX )
            diff2 = abs( numberOfRows/2 - ymin )
            diff1 = diff1 * 2 / numberOfColumns
            diff2 = diff2 * 2 / numberOfRows
            dis = (diff1+diff2)/2
    return 1.0-dis,sz


def there_is_third_person(size,distanceToCenter,thr1,thr2):
  if size > thr1 and distanceToCenter > thr2:
    return True
  return False

def delete_streamers_from_frame(frame,frameNumber,st):
  for s in st:
    xmin,xmax,ymin,ymax,st,en = s
    xmin = int(xmin)
    xmax = int(xmax)
    ymin = int(ymin)
    ymax = int(ymax)
    if frameNumber>=st and frameNumber<=en:
      cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 0, 0), -1)
  return frame

"""# OPENED SCOPE PART"""



"""# SPLIT FUNCTION"""

def modify_isThirdPersonFrame(isThirdPersonFrame,skip,totalframes,minNumberOfZeroFramesToBeCounted):
  result = []
  value = minNumberOfZeroFramesToBeCounted/skip
  value = int(value)
  if minNumberOfZeroFramesToBeCounted%skip ==0:
    value-=1
  ones = []
  #ones.append(-1)
  for i in range(len(isThirdPersonFrame)):
    if isThirdPersonFrame[i] == 1:
      ones.append(i)
  ones.append(len(isThirdPersonFrame))
  for i in range(ones[0]):
    result.extend([0 for i in range(skip)])
  for i in range(len(ones)-1):
    pre = -value -10
    if i !=0:
      pre = ones[i-1]
    cur = ones[i]
    next = ones[i+1]
    elements = next-cur-1
    if cur-pre-1<=value or elements<=value:
      result.extend([1 for i in range(skip)])
    else:
      result.extend([0 for i in range(skip)])
    if elements <=value:
      for j in range(elements):
        result.extend([1 for i in range(skip)])
    else:
      for j in range(elements):
        result.extend([0 for i in range(skip)])
    
  while len(result) > totalframes:
    result.pop()
  return result

# from google.colab.patches import cv2_imshow

def split_video_to_2_videos(videoURL,skip,minNumberOfZeroFramesToBeCounted):
  isThirdPersonFrame = []
  st = get_streamers(videoURL,8,100,0.8,skip)
  cap = cv2.VideoCapture(videoURL)
  if (cap.isOpened()== False): 
    print("Error opening video stream or file")

  frameNumber = 0
  totalFrames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

  while(cap.isOpened()):
    ret, frame = cap.read()
    frameNumber += 1
    if ret == True:
      if frameNumber % skip == 1:
        frame = delete_streamers_from_frame(frame,frameNumber,st)
        frame_rgb = frame[..., ::-1]
        persons = Get_Persons(frame_rgb)
        dis,sz = main_person_size_and_distanceToCenter(persons,frame_rgb)
        titp = there_is_third_person(sz,dis,0.04,0.75)
        if titp:
          isThirdPersonFrame.append(1)
        else:
          isThirdPersonFrame.append(0)
    else:      
      break
  
  cap.release()
  cv2.destroyAllWindows()
  isThirdPersonFrame = modify_isThirdPersonFrame(isThirdPersonFrame,skip,totalFrames,minNumberOfZeroFramesToBeCounted)
  return isThirdPersonFrame

# res = split_video_to_2_videos('/content/gdrive/MyDrive/third person shooter/realm royale_Trim.mp4')

# DEBUGGING
def notThird(res,videoURL):
  skip =10
  st = get_streamers(videoURL,8,100,0.8,skip)
  cap = cv2.VideoCapture(videoURL)
  if (cap.isOpened()== False): 
    print("Error opening video stream or file")

  frameNumber = 0
  totalFrames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

  while(cap.isOpened()):
    ret, frame = cap.read()
    frameNumber += 1
    if frameNumber>200:
      break
    if ret == True:
      if res[frameNumber-1]==0:
        frame = delete_streamers_from_frame(frame,frameNumber,st)
        frame_rgb = frame[..., ::-1]
        persons = Get_Persons(frame_rgb)
        dis,sz = main_person_size_and_distanceToCenter(persons,frame_rgb)
        print(dis)
        print(sz)
        print(frameNumber)
        titp = there_is_third_person(sz,dis,0.04,0.75)
        print(titp)
        dataframe = getDataFrame(persons)
        for i in range(dataframe.shape[0]):
          xmin = dataframe.iloc[i]['xmin']
          xmax = dataframe.iloc[i]['xmax']
          ymin = dataframe.iloc[i]['ymin']
          ymax = dataframe.iloc[i]['ymax']
          xmin = int(xmin)
          xmax = int(xmax)
          ymin = int(ymin)
          ymax = int(ymax)
          cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (255, 0, 0), 2)
        #cv2_imshow(frame)
    else:      
      break
  cap.release()
  cv2.destroyAllWindows()