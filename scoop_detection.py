# -*- coding: utf-8 -*-
"""Scoop detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MwUTil1TKY_YFdYkZfDroAKbp5HaJdAA
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import os
from tensorflow.keras.preprocessing import image
from zipfile import ZipFile

# Commented out IPython magic to ensure Python compatibility.
# importing libraries for Deep Learning
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

import os
os.environ["TF_CPP_MIN_LOG_LEVEL"]="2"
import warnings
warnings.filterwarnings("ignore")

from sklearn.metrics import confusion_matrix,classification_report

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.losses import BinaryCrossentropy
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16, ResNet50

# from google.colab import drive
# drive.mount('/content/drive')

BATCH_SIZE = 32
IMG_WIDTH = 256
IMG_HEIGHT = 256
IMG_CHANNELS = 3
IMG_SHAPE = (IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS)

# creat cnn model
base_model = VGG16(input_shape = IMG_SHAPE, include_top=False, weights='imagenet')
base_model.trainable = False
inputs = Input(shape = IMG_SHAPE)

x = base_model(inputs, training = False)
x = GlobalAveragePooling2D()(x)
x = Dropout(0.5)(x)
outputs = Dense(1, activation='sigmoid')(x)

model = Model(inputs = inputs, outputs = outputs)

reduce_lr = ReduceLROnPlateau(monitor='val_loss', 
                            factor=np.sqrt(0.1),
                             patience=5)

base_learning_rate = 0.001
optimizer = Adam(learning_rate=base_learning_rate)

model.compile(
    optimizer = optimizer,
    loss = BinaryCrossentropy(),
    metrics = ['accuracy']
)

path_to_weights = 'check scope//cp.ckpt'
model.load_weights(path_to_weights)

import cv2
#from google.colab.patches import cv2_imshow

# predict for img 
def testing_image(test_image):
    test_image = cv2.resize(test_image, (IMG_WIDTH, IMG_HEIGHT))
    test_image = image.img_to_array(test_image)
    test_image = np.expand_dims(test_image, axis = 0)
    result = model.predict(x = test_image)
    #print(result)
    if result[0][0]  == 1:
        prediction = 1
    else:
        prediction = 0
    return prediction

def get_scope(path_to_video,skip):
  results = []
  cap = cv2.VideoCapture(path_to_video)
  if cap.isOpened() == False:
    print("Error opening video stream or file")

  frameNumber = 0
  while cap.isOpened():
    ret, frame = cap.read()
    frameNumber +=1
    lastRes = 0
    if ret == True:
      if frameNumber%skip == 1:
        result = testing_image(frame)
        results.append(result)
        lastRes = result
        # if result == 'scope on':
        #   print('result: ', result)
        #   cv2_imshow(frame)
      else:
        results.append(lastRes)
    else:
      break
  cap.release()
  cv2.destroyAllWindows()
  
  return results

# res = testing_video("/content/drive/MyDrive/third person shooter/realm royale_Trim.mp4",10)